{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9548a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from datasets import load_dataset\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596a7b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (C:\\Users\\nil34\\.cache\\huggingface\\datasets\\wikitext\\wikitext-2-raw-v1\\1.0.0\\a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = load_dataset('wikitext', 'wikitext-2-raw-v1', split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5347d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unigram_model():\n",
    "    total_words = 0\n",
    "    unigram_model = {}\n",
    "    for i in range(len(text)):\n",
    "        if text[i]['text'] != \"\":\n",
    "            doc = nlp(text[i]['text'])\n",
    "            lemmas = []\n",
    "            for token in doc:\n",
    "                if token.is_alpha:\n",
    "                    lemmas.append(token.lemma_)\n",
    "\n",
    "            for lemma in lemmas:\n",
    "                unigram_model[lemma] = unigram_model.get(lemma,0) + 1\n",
    "                total_words += 1\n",
    "    \n",
    "    for key in unigram_model:\n",
    "        unigram_model[key] = math.log(unigram_model[key] / total_words)\n",
    "    \n",
    "    return unigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "517b2cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_model = train_unigram_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63250d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bigram_model():\n",
    "    bigram_model = {}\n",
    "    first_words_of_a_bigarm = {}\n",
    "    \n",
    "    for i in range(len(text)):\n",
    "        if text[i]['text'] != \"\":\n",
    "            \n",
    "            doc = nlp(text[i]['text'])\n",
    "            lemmas = [\"START\"]\n",
    "            \n",
    "            for token in doc:\n",
    "                if token.is_alpha:\n",
    "                    lemmas.append(token.lemma_)\n",
    "\n",
    "            for i in range(len(lemmas) - 1):\n",
    "                first_word = lemmas[i]\n",
    "                bigram_key = (lemmas[i],lemmas[i+1]) \n",
    "                bigram_model[bigram_key] = bigram_model.get(bigram_key,0) + 1\n",
    "                first_words_of_a_bigarm[first_word] = first_words_of_a_bigarm.get(first_word,0) + 1\n",
    "\n",
    "    \n",
    "    for key in bigram_model:\n",
    "        bigram_model[key] = math.log(bigram_model[key] / first_words_of_a_bigarm[key[0]])\n",
    "    \n",
    "    return bigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f55934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model = train_bigram_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f5eb52f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next word of the sentence \"I have a house in\" is: the\n"
     ]
    }
   ],
   "source": [
    "def get_the_next_word_for_the_sentence(bigram_model,last_word_of_sentence):\n",
    "    temp_key = \"\"\n",
    "    temp_val = float(\"-inf\")\n",
    "\n",
    "    for key,val in bigram_model.items():\n",
    "        if key[0] == last_word_of_sentence and temp_val < val:\n",
    "            temp_key = key[1]\n",
    "            temp_val = val\n",
    "    \n",
    "    return temp_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "743d7e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probability_of_a_sentence_using_bigram(sentence: str, bigram_model: dict):\n",
    "    doc = nlp(sentence)\n",
    "    lemmas = [\"START\"]\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_alpha:\n",
    "            lemmas.append(token.lemma_)\n",
    "    \n",
    "    total_probability = 0\n",
    "    \n",
    "    for i in range(len(lemmas) - 1):\n",
    "        key_in_bigram = (lemmas[i],lemmas[i+1])\n",
    "        if key_in_bigram in bigram_model:      \n",
    "            total_probability += bigram_model[key_in_bigram]\n",
    "        else:\n",
    "            return float(\"-inf\")\n",
    "    return total_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4df9ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity_using_bigram(corpus,bigram_model):\n",
    "    probability_sum = 0\n",
    "    tokens = []\n",
    "    for line in corpus:\n",
    "        probability_sum += compute_probability_of_a_sentence_using_bigram(line,bigram_model)\n",
    "        doc = nlp(line)\n",
    "        \n",
    "        for token in doc:\n",
    "            if token.is_alpha:\n",
    "                tokens.append(token)\n",
    "        \n",
    "    probability_sum /= len(tokens)\n",
    "    \n",
    "    return math.exp(-probability_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "002a7ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probability_of_a_sentence_using_unigram(sentence: str, unigram_model: dict):\n",
    "    doc = nlp(sentence)\n",
    "    lemmas = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_alpha:\n",
    "            lemmas.append(token.lemma_)\n",
    "    \n",
    "    total_probability = 0\n",
    "    \n",
    "    for lemma in lemmas:\n",
    "        if lemma in unigram_model:\n",
    "            total_probability += unigram_model[lemma]\n",
    "        else:\n",
    "            return float(\"-inf\")\n",
    "    return total_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1197a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_interpolated_probability(sentence,bigram_model,unigram_model,weight_bigram,weight_unigram):\n",
    "    \n",
    "    doc = nlp(sentence)\n",
    "    lemmas = [\"START\"]\n",
    "    \n",
    "    result = 0\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_alpha:\n",
    "            lemmas.append(token.lemma_)\n",
    "            \n",
    "    for i in range(len(lemmas) - 1):\n",
    "        key_in_unigram = lemmas[i+1]\n",
    "        key_in_bigram = (lemmas[i],lemmas[i+1])\n",
    "        unigram_calculation = 0\n",
    "        bigram_calculation = 0\n",
    "        if key_in_unigram in unigram_model:\n",
    "            unigram_calculation = math.exp(unigram_model[key_in_unigram])*weight_unigram\n",
    "        if key_in_bigram in bigram_model:\n",
    "            bigram_calculation = math.exp(bigram_model[key_in_bigram])*weight_bigram\n",
    "        calculation = bigram_calculation + unigram_calculation\n",
    "        result += math.log(calculation)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2d310867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269.81031430478953"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_perplexity_using_interpolated_model(corpus,bigram_model,unigram_model,weight_bigram,weight_unigram):\n",
    "    probability_sum = 0\n",
    "    tokens = []\n",
    "    for line in corpus:\n",
    "        probability_sum += calculate_interpolated_probability(line,bigram_model,unigram_model,weight_bigram,weight_unigram)\n",
    "        doc = nlp(line)\n",
    "\n",
    "        for token in doc:\n",
    "            if token.is_alpha:\n",
    "                tokens.append(token)\n",
    "        \n",
    "    probability_sum /= len(tokens)\n",
    "    return math.exp(-probability_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ffcfd1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next word of the sentence \"I have a house in\" is: the\n",
      "The probability for the sentence Brad Pitt was born in Oklahoma is: -inf\n",
      "The probability for the sentence The actor was born in USA is: -29.686567347483418\n",
      "The perplexity of both the sentences is: inf\n",
      "The probability of the first sentence using the new model is: -36.176302610738425\n",
      "The probability of the second sentence using the new model is: -30.996327459140225\n",
      "The perplexity of both the sentences with the new model is: 269.81031430478953\n"
     ]
    }
   ],
   "source": [
    "first_sentence = \"Brad Pitt was born in Oklahoma\"\n",
    "second_sentence = \"The actor was born in USA\"\n",
    "corpus = [\"Brad Pitt was born in Oklahoma\",\"The actor was born in USA\"]\n",
    "\n",
    "print('The prediction of the next word for the sentence \"I have a house in\" is: ' + get_the_next_word_for_the_sentence(bigram_model,\"in\"))\n",
    "print(\"The probability for the sentence \" + first_sentence + \" is: \" + (str)(compute_probability_of_a_sentence_using_bigram(first_sentence,bigram_model)))\n",
    "print(\"The probability for the sentence \" + second_sentence + \" is: \" + (str)(compute_probability_of_a_sentence_using_bigram(second_sentence,bigram_model)))\n",
    "print(\"The perplexity of both the sentences is: \" + (str)(calculate_perplexity_using_bigram(corpus,bigram_model)))\n",
    "print(\"The probability of the first sentence using the new model is: \"+ (str)(calculate_interpolated_probability(first_sentence,bigram_model,unigram_model,2/3,1/3)))\n",
    "print(\"The probability of the second sentence using the new model is: \" + (str)(calculate_interpolated_probability(second_sentence,bigram_model,unigram_model,2/3,1/3)))\n",
    "print(\"The perplexity of both the sentences with the new model is: \" + (str)(calculate_perplexity_using_interpolated_model(corpus,bigram_model,unigram_model,2/3,1/3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a9926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d63b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
